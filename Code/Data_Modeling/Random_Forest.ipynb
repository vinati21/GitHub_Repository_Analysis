{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data base\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import MySQLdb\n",
    "\n",
    "#importing pickle\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Importing bokeh\n",
    "\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.palettes import Spectral6\n",
    "from bokeh.models import ColumnDataSource\n",
    "\n",
    "#Feature selection\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# for splitting the data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#tf-idf libraries \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#importing truncated svd for LSA- Latent Semantic Analysis\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "#Importing tsne\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "#Label Encoding\n",
    "# import labelencoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Random forest Tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "#For tuning the hyper-parameters\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#importing metrics\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-bd4c39f4c5e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#svd data train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/isiia/Github_Classification/Pickles/svd_train.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0msvd_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m#svd data test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "# UnPickling all the files so that I can use it for modeling\n",
    "\n",
    "\n",
    "# X_train\n",
    "with open('/home/isiia/Github_Classification/Pickles/X_train.pickle', 'rb') as data:\n",
    "    X_train= pickle.load(data)\n",
    "    \n",
    "# X_test    \n",
    "with open('/home/isiia/Github_Classification/Pickles/X_test.pickle', 'rb') as data:\n",
    "    X_test=pickle.load(data)\n",
    "    \n",
    "# y_train\n",
    "with open('/home/isiia/Github_Classification/Pickles/Y_train.pickle', 'rb') as data:\n",
    "    Y_train=pickle.load(data)\n",
    "    \n",
    "# y_test\n",
    "with open('/home/isiia/Github_Classification/Pickles/Y_test.pickle', 'rb') as data:\n",
    "    Y_test=pickle.load(data)\n",
    "    \n",
    "# df\n",
    "with open('/home/isiia/Github_Classification/Pickles/df_repo.pickle', 'rb') as data:\n",
    "    df_repo=pickle.load(data)\n",
    "    \n",
    "# Tf-idf vectorized train dataset\n",
    "with open('/home/isiia/Github_Classification/Pickles/vz_train.pickle', 'rb') as data:\n",
    "    vz_train=pickle.load(data)\n",
    "\n",
    "# Tf-idf vectorized test dataset\n",
    "with open('/home/isiia/Github_Classification/Pickles/vz_test.pickle', 'rb') as data:\n",
    "    vz_test=pickle.load(data)\n",
    "\n",
    "# Class dictionary\n",
    "with open('/home/isiia/Github_Classification/Pickles/class_dict.pickle', 'rb') as data:\n",
    "    class_dict=pickle.load(data)\n",
    "\n",
    "#tfidf data frame for train\n",
    "with open('/home/isiia/Github_Classification/Pickles/tfidf_df.pickle', 'rb') as data:\n",
    "    tfidf_df=pickle.load(data)\n",
    "    \n",
    "#svd data train\n",
    "with open('/home/isiia/Github_Classification/Pickles/svd_train.pickle', 'rb') as data:\n",
    "    svd_train=pickle.load(data)\n",
    "\n",
    "#svd data test\n",
    "with open('/home/isiia/Github_Classification/Pickles/svd_test.pickle', 'rb') as data:\n",
    "    svd_test=pickle.load(data)\n",
    "    \n",
    "#svd data train dataframe\n",
    "with open('/home/isiia/Github_Classification/Pickles/df_svd_train.pickle', 'rb') as data:\n",
    "    df_svd_train=pickle.load(data)\n",
    "\n",
    "#svd data test dataframe\n",
    "with open('/home/isiia/Github_Classification/Pickles/df_svd_test.pickle', 'rb') as data:\n",
    "    df_svd_test=pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03260996,  0.01461761,  0.00949102, ..., -0.00071929,\n",
       "         0.00128033, -0.00350475],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        , -0.        ],\n",
       "       [ 0.0485865 ,  0.03370597,  0.01822184, ...,  0.00358654,\n",
       "         0.00356545,  0.0030441 ],\n",
       "       ...,\n",
       "       [ 0.0237373 ,  0.01203784,  0.01119664, ...,  0.01142357,\n",
       "        -0.00253359, -0.00551639],\n",
       "       [ 0.01443377,  0.00808581,  0.00805301, ..., -0.00025604,\n",
       "         0.00880142, -0.01009398],\n",
       "       [ 0.00142174,  0.000177  ,  0.00123491, ...,  0.00056181,\n",
       "         0.0001802 ,  0.00010293]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model=RandomForestClassifier()\n",
    "svd_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(411712, 500)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isiia/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111.69777941703796\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0=time.time()\n",
    "base_model.fit(svd_train,Y_train.values)\n",
    "t1=time.time()-t0\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score is \n",
      "75.12411588683352\n",
      "The test score is\n",
      "31.764923053007927\n"
     ]
    }
   ],
   "source": [
    "print(\"The training score is \")\n",
    "print(base_model.score(svd_train,Y_train.values)*100)\n",
    "\n",
    "print(\"The test score is\")\n",
    "print(base_model.score(svd_test,Y_test.values)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_new=RandomForestClassifier(n_estimators=200,max_depth=300,n_jobs=-1,min_samples_leaf=4,min_samples_split=4,warm_start=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  8.6min\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0=time.time()\n",
    "base_model_new.fit(vz_train.toarray(),Y_train.values)\n",
    "t1=time.time()-t0 \n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score is \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.81396704492461\n",
      "The test score is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36.02129644023007"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The training score is \")\n",
    "print(base_model_new.score(vz_train.toarray(),Y_train.values)*100)\n",
    "\n",
    "print(\"The test score is\")\n",
    "base_model_new.score(vz_test.toarray(),Y_test.values)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## max_depth =20, n=200\n",
    "### The training score is 53.583815871288664\n",
    "### The test score is 35.29166018964713\n",
    "\n",
    "## max_depth= 20, n=400\n",
    "### The training score is 53.583815871288664\n",
    "### The test score is 35.29166018964713\n",
    "\n",
    "\n",
    "# Therefore we can say that we can fix n=200\n",
    "\n",
    "## max_depth= 10, n=200\n",
    "### The training score is 44.31884424063423\n",
    "### The test score is 35.68805378517021\n",
    "\n",
    "## max_depth =20, n=200\n",
    "### The training score is 53.583815871288664\n",
    "### The test score is 35.29166018964713\n",
    "\n",
    "## max_depth= 30, n=200\n",
    "### The training score is 61.51023045235504\n",
    "### The test score is 34.46098243432302"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If we see the above results implies that the model is overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets Tune the RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using RandomizedGridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200], 'bootstrap': ['False'], 'criterion': ['gini'], 'max_depth': [30], 'max_features': ['log2'], 'min_samples_leaf': [2, 4, 6, 8, 10], 'min_samples_split': [2, 5, 10]}\n"
     ]
    }
   ],
   "source": [
    "# I will be selecting criterion, max_depth, max_features,min_samples_leaf,min_samples_split,bootstrap,n_estimators\n",
    "# defining a range for all of these\n",
    "\n",
    "n_estimators = [200]\n",
    "bootstrap=['False']\n",
    "criterion=['gini']\n",
    "# max_depth\n",
    "max_depth = [30]\n",
    "#max_depth.append(None)\n",
    "\n",
    "max_features=['log2']\n",
    "min_samples_leaf=[2,4,6,8,10]\n",
    "min_samples_split=[2,5,10]\n",
    "\n",
    "random_grid={'n_estimators':n_estimators,'bootstrap':bootstrap,'criterion':criterion, 'max_depth':max_depth, 'max_features':max_features,'min_samples_leaf':min_samples_leaf,'min_samples_split':min_samples_split}\n",
    "print(random_grid)\n",
    "\n",
    "random_search=RandomizedSearchCV(estimator=base_model,param_distributions=random_grid,scoring='accuracy',cv=5,return_train_score=True,n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isiia/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-191fe17da8c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvd_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    685\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1466\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1467\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1468\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    664\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 666\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random_search.fit(svd_train,Y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best params are:\",random_search.best_params_)\n",
    "print(\"The best estimator is :\",random_search.best_estimator_)\n",
    "print(\"The best score is :\",random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the gridsearchcv based on the outputs of randomsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators=[i for i in range(500,1000)]\n",
    "bootstrap=['False']\n",
    "criterion=['entropy']\n",
    "max_depth=[i for i in range(1,10)]\n",
    "max_features=['sqrt']\n",
    "min_samples_leaf=[2,3,4]\n",
    "min_samples_split=[10,11,12]\n",
    "grid={'n_estimators':n_estimators,'bootstrap':bootstrap,'criterion':criterion, 'max_depth':max_depth, 'max_features':max_features,'min_samples_leaf':min_samples_leaf,'min_samples_split':min_samples_split}\n",
    "print(grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search=GridSearchCV(estimator=base_model,param_grid=grid,scoring='accuracy',cv=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train,Y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best estimator is:\",grid_search.best_estimator_)\n",
    "\n",
    "print(\"The best params are:\",grid_search.best_params_)\n",
    "\n",
    "print(\"The best accuracy is\",grid_search.best_score_*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training accuracy\n",
    "print(\"The training accuracy is: \")\n",
    "train_acc=accuracy_score(Y_train, grid_search.predict(X_train))*100\n",
    "print(train_acc)\n",
    "\n",
    "#Test Accuracy\n",
    "print(\"The test accuracy is: \")\n",
    "test_acc=accuracy_score(Y_test, grid_search.predict(X_test))*100\n",
    "print(test_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conf_matrix=confusion_matrix(Y_test, grid_search.predict(X_test))\n",
    "sns.heatmap(data=Conf_matrix,annot=True,yticklabels=([\"No\",\"Yes\"]),xticklabels=([\"No\",\"Yes\"]));\n",
    "plt.xlabel(\"Actual\",fontsize=20);\n",
    "plt.ylabel(\"Predicted\",fontsize=20);\n",
    "plt.title(\"Confusion Matrix\",fontsize=30);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving decision tree accuracies into dataframe\n",
    "\n",
    "df_model_current=pd.DataFrame({'Model':[\"Decision Tree\"],'Train_Accuracy':[train_acc],'Test_Accuracy':[test_acc]},index=[1])\n",
    "\n",
    "df_model=pd.concat([df_model,df_model_current],axis=0)\n",
    "\n",
    "df_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling dataframe\n",
    "with open('/Users/vinatigattupalli/Diabetes-Detection/Pickles/df_model.pickle','wb') as output:\n",
    "    pickle.dump(df_model, output)\n",
    "\n",
    "\n",
    "\n",
    "#pickling DT model\n",
    "with open('/Users/vinatigattupalli/Diabetes-Detection/Pickles/RandomForest.pickle','wb') as output:\n",
    "    pickle.dump(grid_search, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
