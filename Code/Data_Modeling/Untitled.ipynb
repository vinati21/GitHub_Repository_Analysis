{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rf_model='/home/isiia/Github_Classification/Code/Data_Modeling/RF.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/isiia/Github_Classification/Code/Data_Modeling/RF.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $Rf_model\n",
    "\n",
    "# data base\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import MySQLdb\n",
    "\n",
    "#importing pickle\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Importing bokeh\n",
    "\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.palettes import Spectral6\n",
    "from bokeh.models import ColumnDataSource\n",
    "\n",
    "#Feature selection\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# for splitting the data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#tf-idf libraries \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#importing truncated svd for LSA- Latent Semantic Analysis\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "#Importing tsne\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "#Label Encoding\n",
    "# import labelencoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "# Importing Decision Tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "#For tuning the hyper-parameters\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#importing metrics\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# UnPickling all the files so that I can use it for modeling\n",
    "\n",
    "\n",
    "# X_train\n",
    "with open('/home/isiia/Github_Classification/Pickles/X_train.pickle', 'rb') as data:\n",
    "    X_train= pickle.load(data)\n",
    "    \n",
    "# X_test    \n",
    "with open('/home/isiia/Github_Classification/Pickles/X_test.pickle', 'rb') as data:\n",
    "    X_test=pickle.load(data)\n",
    "    \n",
    "# y_train\n",
    "with open('/home/isiia/Github_Classification/Pickles/Y_train.pickle', 'rb') as data:\n",
    "    Y_train=pickle.load(data)\n",
    "    \n",
    "# y_test\n",
    "with open('/home/isiia/Github_Classification/Pickles/Y_test.pickle', 'rb') as data:\n",
    "    Y_test=pickle.load(data)\n",
    "    \n",
    "# df\n",
    "with open('/home/isiia/Github_Classification/Pickles/df_repo.pickle', 'rb') as data:\n",
    "    df_repo=pickle.load(data)\n",
    "    \n",
    "# Tf-idf vectorized train dataset\n",
    "with open('/home/isiia/Github_Classification/Pickles/vz_train.pickle', 'rb') as data:\n",
    "    vz_train=pickle.load(data)\n",
    "\n",
    "# Tf-idf vectorized test dataset\n",
    "with open('/home/isiia/Github_Classification/Pickles/vz_test.pickle', 'rb') as data:\n",
    "    vz_test=pickle.load(data)\n",
    "\n",
    "# Class dictionary\n",
    "with open('/home/isiia/Github_Classification/Pickles/class_dict.pickle', 'rb') as data:\n",
    "    class_dict=pickle.load(data)\n",
    "\n",
    "#tfidf data frame for train\n",
    "with open('/home/isiia/Github_Classification/Pickles/tfidf_df.pickle', 'rb') as data:\n",
    "    tfidf_df=pickle.load(data)\n",
    "    \n",
    "# #svd data train\n",
    "# with open('/home/isiia/Github_Classification/Pickles/svd_train.pickle', 'rb') as data:\n",
    "#     svd_train=pickle.load(data)\n",
    "\n",
    "# #svd data test\n",
    "# with open('/home/isiia/Github_Classification/Pickles/svd_test.pickle', 'rb') as data:\n",
    "#     svd_test=pickle.load(data)\n",
    "    \n",
    "# #svd data train dataframe\n",
    "# with open('/home/isiia/Github_Classification/Pickles/df_svd_train.pickle', 'rb') as data:\n",
    "#     df_svd_train=pickle.load(data)\n",
    "\n",
    "# #svd data test dataframe\n",
    "# with open('/home/isiia/Github_Classification/Pickles/df_svd_test.pickle', 'rb') as data:\n",
    "#     df_svd_test=pickle.load(data)\n",
    "\n",
    "base_model=RandomForestClassifier()\n",
    "# svd_train\n",
    "\n",
    "# import time\n",
    "# t0=time.time()\n",
    "# base_model.fit(svd_train,Y_train.values)\n",
    "# t1=time.time()-t0\n",
    "# print(\"Time Taken for base model is\",t1)\n",
    "\n",
    "# print(\"The training score is \")\n",
    "# print(base_model.score(svd_train,Y_train.values)*100)\n",
    "\n",
    "# print(\"The test score is\")\n",
    "# base_model.score(svd_test,Y_test.values)*100\n",
    "\n",
    "base_model_new=RandomForestClassifier(n_estimators=200,max_depth=350,n_jobs=-1,min_samples_leaf=4,min_samples_split=4,warm_start=True,verbose=1)\n",
    "import time\n",
    "t0=time.time()\n",
    "base_model_new.fit(vz_train.toarray(),Y_train.values)\n",
    "t1=time.time()-t0\n",
    "print(t1)\n",
    "\n",
    "print(\"The training score is \")\n",
    "print(base_model_new.score(vz_train.toarray(),Y_train.values)*100)\n",
    "\n",
    "print(\"The test score is\")\n",
    "base_model_new.score(vz_test.toarray(),Y_test.values)*100\n",
    "\n",
    "## If we see the above results implies that the model is overfitting.\n",
    "\n",
    "## Lets Tune the RandomForest\n",
    "\n",
    "base_model.get_params\n",
    "\n",
    "## Using RandomizedGridSearchCV\n",
    "\n",
    "# I will be selecting criterion, max_depth, max_features,min_samples_leaf,min_samples_split,bootstrap,n_estimators\n",
    "# defining a range for all of these\n",
    "\n",
    "n_estimators = [200]\n",
    "bootstrap=['False']\n",
    "criterion=['gini']\n",
    "# max_depth\n",
    "max_depth = [350]\n",
    "#max_depth.append(None)\n",
    "\n",
    "max_features=['log2']\n",
    "min_samples_leaf=[2,4,6,8,10]\n",
    "min_samples_split=[2,5,10]\n",
    "\n",
    "random_grid={'n_estimators':n_estimators,'bootstrap':bootstrap,'criterion':criterion, 'max_depth':max_depth, 'max_features':max_features,'min_samples_leaf':min_samples_leaf,'min_samples_split':min_samples_split}\n",
    "print(random_grid)\n",
    "\n",
    "random_search=RandomizedSearchCV(estimator=base_model,param_distributions=random_grid,scoring='accuracy',cv=5,return_train_score=True,n_jobs=-1)\n",
    "\n",
    "t0=time.time()\n",
    "random_search.fit(vz_train.toarray(),Y_train.values)\n",
    "t1=time.time()-t0\n",
    "print(\"Time taken for Random Search CV is \",t1)\n",
    "print(\"The best params are:\",random_search.best_params_)\n",
    "print(\"The best estimator is :\",random_search.best_estimator_)\n",
    "print(\"The best score is :\",random_search.best_score_)\n",
    "\n",
    "# Training accuracy\n",
    "print(\"The training accuracy is: \")\n",
    "train_acc=accuracy_score(Y_train, random_search.predict(vz_train.toarray()))*100\n",
    "print(train_acc)\n",
    "\n",
    "#Test Accuracy\n",
    "print(\"The test accuracy is: \")\n",
    "test_acc=accuracy_score(Y_test, random_search.predict(vz_test.toarray()))*100\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/isiia/Github_Classification/Code/Data_Modeling'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
